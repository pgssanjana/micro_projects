{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pgssanjana/micro_projects/blob/main/face_recognition_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74,
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "ok": true,
              "status": 200,
              "status_text": ""
            }
          }
        },
        "id": "kVaGNeACGsPx",
        "outputId": "8142e04c-ebb2-4e85-aaf2-c2ad8a1d847e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-f07460a6-268b-4243-b55f-781642289dc7\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-f07460a6-268b-4243-b55f-781642289dc7\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        }
      ],
      "source": [
        "!pip install -q kaggle\n",
        "from google.colab import files\n",
        "files.upload()\n",
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json\n",
        "# ! kaggle datasets list\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lM81wvDwGu66",
        "outputId": "015c3a71-f9bf-4a4e-9655-510748ae2ce4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading face-recognition-30.zip to /content\n",
            " 99% 638M/641M [00:04<00:00, 118MB/s]\n",
            "100% 641M/641M [00:04<00:00, 142MB/s]\n"
          ]
        }
      ],
      "source": [
        "!kaggle datasets download -d pramod722445/face-recognition-30\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "3LxTxk-uGu9O"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "zf = \"/content/face-recognition-30.zip\"\n",
        "target_dir = \"/content/input/face-recognition-30/dataset\"\n",
        "zfile = zipfile.ZipFile(zf)\n",
        "zfile.extractall(target_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "g_NnFsj7Gu_0"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "\n",
        "# style your matplotlib\n",
        "mpl.style.use(\"seaborn-darkgrid\")\n",
        "# run this block\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "qCp2b82hGvCS"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j4VEWHlJGvEj",
        "outputId": "3368f062-495a-4736-f58e-e1791d038aa9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Jim_Parsons',\n",
              " 'Matthew_Perry',\n",
              " 'dhoni',\n",
              " 'virat_kohli',\n",
              " 'mohamed_ali',\n",
              " 'aishwarya_rai',\n",
              " 'random_person',\n",
              " 'Simon_Helberg',\n",
              " 'ronaldo',\n",
              " 'Courteney_Cox',\n",
              " 'Matt_LeBlanc',\n",
              " 'angelina_jolie',\n",
              " 'brad_pitt',\n",
              " 'sylvester_stallone',\n",
              " 'Kunal_Nayya',\n",
              " 'Jennifer_Aniston',\n",
              " 'scarlett_johansson',\n",
              " 'pewdiepie',\n",
              " 'Lisa_Kudrow',\n",
              " 'arnold_schwarzenegger',\n",
              " 'Pankaj_Tripathi',\n",
              " 'hardik_pandya',\n",
              " 'David_Schwimmer',\n",
              " 'messi',\n",
              " 'Sachin_Tendulka',\n",
              " 'ROHIT_SHARMA',\n",
              " 'Johnny_Galeck',\n",
              " 'manoj_bajpayee',\n",
              " 'suresh_raina',\n",
              " 'bhuvan_bam']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "files=os.listdir(\"/content/input/face-recognition-30/dataset/dataset/\")\n",
        "files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q9MAXZMDGvHH",
        "outputId": "a6ff3fce-0f48-4f3d-e508-f22878ef8787"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 639/639 [00:01<00:00, 333.24it/s]\n",
            "100%|██████████| 530/530 [00:01<00:00, 418.69it/s]\n",
            "100%|██████████| 314/314 [00:00<00:00, 940.56it/s]\n",
            "100%|██████████| 391/391 [00:00<00:00, 483.61it/s]\n",
            "100%|██████████| 338/338 [00:00<00:00, 435.63it/s]\n",
            "100%|██████████| 711/711 [00:02<00:00, 353.49it/s]\n",
            "100%|██████████| 2250/2250 [00:02<00:00, 886.24it/s]\n",
            "100%|██████████| 484/484 [00:01<00:00, 408.44it/s]\n",
            "100%|██████████| 418/418 [00:00<00:00, 509.51it/s]\n",
            "100%|██████████| 702/702 [00:02<00:00, 301.91it/s]\n",
            "100%|██████████| 449/449 [00:01<00:00, 364.33it/s]\n",
            "100%|██████████| 465/465 [00:02<00:00, 229.10it/s]\n",
            "100%|██████████| 552/552 [00:01<00:00, 296.28it/s]\n",
            "100%|██████████| 480/480 [00:01<00:00, 400.56it/s]\n",
            "100%|██████████| 532/532 [00:00<00:00, 617.77it/s]\n",
            "100%|██████████| 639/639 [00:02<00:00, 294.54it/s]\n",
            "100%|██████████| 507/507 [00:02<00:00, 215.95it/s]\n",
            "100%|██████████| 395/395 [00:00<00:00, 509.95it/s]\n",
            "100%|██████████| 640/640 [00:02<00:00, 295.01it/s]\n",
            "100%|██████████| 553/553 [00:01<00:00, 404.84it/s]\n",
            "100%|██████████| 354/354 [00:00<00:00, 681.56it/s]\n",
            "100%|██████████| 292/292 [00:00<00:00, 828.56it/s]\n",
            "100%|██████████| 537/537 [00:01<00:00, 299.16it/s]\n",
            "100%|██████████| 432/432 [00:00<00:00, 499.25it/s]\n",
            "100%|██████████| 354/354 [00:00<00:00, 384.13it/s]\n",
            "100%|██████████| 265/265 [00:00<00:00, 660.05it/s] \n",
            "100%|██████████| 508/508 [00:01<00:00, 299.69it/s]\n",
            "100%|██████████| 457/457 [00:00<00:00, 863.79it/s]\n",
            "100%|██████████| 319/319 [00:00<00:00, 1340.65it/s]\n",
            "100%|██████████| 382/382 [00:00<00:00, 864.12it/s]\n"
          ]
        }
      ],
      "source": [
        "image_array=[]  # it's a list later i will convert it to array\n",
        "label_array=[]\n",
        "path=\"/content/input/face-recognition-30/dataset/dataset/\"\n",
        "# loop through each sub-folder in train\n",
        "for i in range(len(files)):\n",
        "    # files in sub-folder\n",
        "    file_sub=os.listdir(path+files[i])\n",
        "\n",
        "    for k in tqdm(range(len(file_sub))):\n",
        "        try:\n",
        "            img=cv2.imread(path+files[i]+\"/\"+file_sub[k])\n",
        "            img=cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
        "            img=cv2.resize(img,(96,96))\n",
        "            image_array.append(img)\n",
        "            label_array.append(i)\n",
        "        except:\n",
        "            pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MLa637mRJD4N",
        "outputId": "c818341a-8fcf-4aac-a8ef-fd9cb732811a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "88"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "import gc\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "ejeSc5xLJD1o"
      },
      "outputs": [],
      "source": [
        "image_array=np.array(image_array)/255.0\n",
        "label_array=np.array(label_array)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "KUi9FBYvJDzS"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,Y_train,Y_test=train_test_split(image_array,label_array,test_size=0.15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "hngjBIXiJDwb"
      },
      "outputs": [],
      "source": [
        "from keras import layers,callbacks,utils,applications,optimizers\n",
        "from keras.models import Sequential,Model,load_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H2SQECTuGvJw",
        "outputId": "cdf34e02-1033-488a-c725-b05be2336379"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "len(files)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "hByioZFKJ7hW"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "# from keras.applications import MobileNet\n",
        "from keras.applications.mobilenet import preprocess_input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "SBZefzqZMA2l"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications.resnet50 import ResNet50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "DhDgzmyAMtTm"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nxy3PBeGJm8K",
        "outputId": "b8a205d8-f836-480e-ee8f-c953bf6790c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " mobilenetv2_1.00_96 (Functi  (None, 3, 3, 1280)       2257984   \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " global_average_pooling2d_1   (None, 1280)             0         \n",
            " (GlobalAveragePooling2D)                                        \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 1280)              0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 1281      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,259,265\n",
            "Trainable params: 2,225,153\n",
            "Non-trainable params: 34,112\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "\n",
        "model=Sequential()\n",
        "# I will use MobileNetV2 as an pretrained model \n",
        "pretrained_model=MobileNetV2(input_shape=(96,96,3),include_top=False,\n",
        "                                         weights=\"imagenet\")\n",
        "model.add(pretrained_model)\n",
        "model.add(layers.GlobalAveragePooling2D())\n",
        "# add dropout to increase accuracy by not overfitting\n",
        "model.add(layers.Dropout(0.3))\n",
        "# add dense layer as final output\n",
        "model.add(layers.Dense(1))\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "JBioWjzNLIgf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "xUuxnhXBJm5l"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer=\"adam\",loss=\"mean_squared_error\",metrics=[\"mae\"])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "UhaGKyvNJm29"
      },
      "outputs": [],
      "source": [
        "\n",
        "ckp_path=\"trained_model/model\"\n",
        "model_checkpoint=tf.keras.callbacks.ModelCheckpoint(filepath=ckp_path,\n",
        "                                                   monitor=\"val_mae\",\n",
        "                                                   mode=\"auto\",\n",
        "                                                   save_best_only=True,\n",
        "                                                   save_weights_only=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "L6H8N-nhJm0W"
      },
      "outputs": [],
      "source": [
        "# create a lr reducer which decrease learning rate when accuarcy does not increase\n",
        "reduce_lr=tf.keras.callbacks.ReduceLROnPlateau(factor=0.9,monitor=\"val_mae\",\n",
        "                                             mode=\"auto\",cooldown=0,\n",
        "                                             patience=5,verbose=1,min_lr=1e-6)\n",
        "# patience : wait till 5 epoch\n",
        "# verbose : show accuracy every 1 epoch\n",
        "# min_lr=minimum learning rate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "nmqxqiWKPIP_"
      },
      "outputs": [],
      "source": [
        "# import tensorflow as tf\n",
        "# my_callbacks = [\n",
        "#     tf.keras.callbacks.EarlyStopping(patience=2),\n",
        "#     tf.keras.callbacks.ModelCheckpoint(filepath='model.{epoch:02d}-{val_loss:.2f}.h5',\n",
        "#                               monitor='val_loss',\n",
        "#                              verbose=1, \n",
        "#                              save_best_only=True),\n",
        "#     tf.keras.callbacks.TensorBoard(log_dir='./logs'),\n",
        "# ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5TPC7V3cND0P",
        "outputId": "4b77e6e2-728d-459b-be2c-abb0e4efcaa5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "128/128 [==============================] - 32s 113ms/step - loss: 51.1929 - mae: 5.3230 - val_loss: 180.3858 - val_mae: 11.6756 - lr: 0.0010\n",
            "Epoch 2/150\n",
            "128/128 [==============================] - 12s 92ms/step - loss: 22.9158 - mae: 3.4151 - val_loss: 296.6952 - val_mae: 15.7995 - lr: 0.0010\n",
            "Epoch 3/150\n",
            "128/128 [==============================] - 12s 91ms/step - loss: 18.8766 - mae: 2.9621 - val_loss: 504.3993 - val_mae: 20.5910 - lr: 0.0010\n",
            "Epoch 4/150\n",
            "128/128 [==============================] - 12s 91ms/step - loss: 16.3437 - mae: 2.7420 - val_loss: 195.2178 - val_mae: 12.4348 - lr: 0.0010\n",
            "Epoch 5/150\n",
            "128/128 [==============================] - 11s 87ms/step - loss: 13.8546 - mae: 2.4659 - val_loss: 228.6660 - val_mae: 13.3170 - lr: 0.0010\n",
            "Epoch 6/150\n",
            "128/128 [==============================] - ETA: 0s - loss: 10.0804 - mae: 2.0625\n",
            "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0009000000427477062.\n",
            "128/128 [==============================] - 12s 91ms/step - loss: 10.0804 - mae: 2.0625 - val_loss: 206.6476 - val_mae: 12.8548 - lr: 0.0010\n",
            "Epoch 7/150\n",
            "128/128 [==============================] - 11s 89ms/step - loss: 9.0235 - mae: 1.9402 - val_loss: 64.5519 - val_mae: 6.7712 - lr: 9.0000e-04\n",
            "Epoch 8/150\n",
            "128/128 [==============================] - 11s 89ms/step - loss: 8.6788 - mae: 1.9038 - val_loss: 67.6550 - val_mae: 7.0834 - lr: 9.0000e-04\n",
            "Epoch 9/150\n",
            "128/128 [==============================] - 11s 86ms/step - loss: 8.1662 - mae: 1.8332 - val_loss: 109.8270 - val_mae: 9.2875 - lr: 9.0000e-04\n",
            "Epoch 10/150\n",
            "128/128 [==============================] - 11s 86ms/step - loss: 8.2699 - mae: 1.8224 - val_loss: 73.9915 - val_mae: 7.2208 - lr: 9.0000e-04\n",
            "Epoch 11/150\n",
            "128/128 [==============================] - 11s 86ms/step - loss: 8.5565 - mae: 1.8877 - val_loss: 150.7231 - val_mae: 10.5975 - lr: 9.0000e-04\n",
            "Epoch 12/150\n",
            "128/128 [==============================] - ETA: 0s - loss: 9.4473 - mae: 1.9431\n",
            "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0008100000384729356.\n",
            "128/128 [==============================] - 11s 87ms/step - loss: 9.4473 - mae: 1.9431 - val_loss: 83.2206 - val_mae: 7.0920 - lr: 9.0000e-04\n",
            "Epoch 13/150\n",
            "128/128 [==============================] - 11s 90ms/step - loss: 7.7808 - mae: 1.7591 - val_loss: 65.8005 - val_mae: 6.6646 - lr: 8.1000e-04\n",
            "Epoch 14/150\n",
            "128/128 [==============================] - 11s 86ms/step - loss: 5.0620 - mae: 1.4239 - val_loss: 96.6668 - val_mae: 7.8091 - lr: 8.1000e-04\n",
            "Epoch 15/150\n",
            "128/128 [==============================] - 12s 90ms/step - loss: 5.1887 - mae: 1.4204 - val_loss: 80.8154 - val_mae: 7.5401 - lr: 8.1000e-04\n",
            "Epoch 16/150\n",
            "128/128 [==============================] - 11s 88ms/step - loss: 6.5747 - mae: 1.6573 - val_loss: 54.9898 - val_mae: 5.8007 - lr: 8.1000e-04\n",
            "Epoch 17/150\n",
            "128/128 [==============================] - 11s 88ms/step - loss: 4.2165 - mae: 1.3114 - val_loss: 45.5183 - val_mae: 5.4767 - lr: 8.1000e-04\n",
            "Epoch 18/150\n",
            "128/128 [==============================] - 12s 91ms/step - loss: 3.6992 - mae: 1.2043 - val_loss: 62.2807 - val_mae: 6.4154 - lr: 8.1000e-04\n",
            "Epoch 19/150\n",
            "128/128 [==============================] - 11s 89ms/step - loss: 4.3077 - mae: 1.3645 - val_loss: 29.7381 - val_mae: 4.1959 - lr: 8.1000e-04\n",
            "Epoch 20/150\n",
            "128/128 [==============================] - 12s 91ms/step - loss: 4.8398 - mae: 1.3415 - val_loss: 44.5483 - val_mae: 4.9453 - lr: 8.1000e-04\n",
            "Epoch 21/150\n",
            "128/128 [==============================] - 12s 91ms/step - loss: 2.8325 - mae: 1.0781 - val_loss: 31.5429 - val_mae: 3.9358 - lr: 8.1000e-04\n",
            "Epoch 22/150\n",
            "128/128 [==============================] - 11s 86ms/step - loss: 4.1142 - mae: 1.2187 - val_loss: 48.0780 - val_mae: 5.0873 - lr: 8.1000e-04\n",
            "Epoch 23/150\n",
            "128/128 [==============================] - 12s 91ms/step - loss: 4.0431 - mae: 1.2164 - val_loss: 35.0434 - val_mae: 4.1263 - lr: 8.1000e-04\n",
            "Epoch 24/150\n",
            "128/128 [==============================] - 11s 90ms/step - loss: 3.8641 - mae: 1.2022 - val_loss: 44.9317 - val_mae: 5.0144 - lr: 8.1000e-04\n",
            "Epoch 25/150\n",
            "128/128 [==============================] - 11s 86ms/step - loss: 3.3713 - mae: 1.1413 - val_loss: 35.6371 - val_mae: 4.4843 - lr: 8.1000e-04\n",
            "Epoch 26/150\n",
            "128/128 [==============================] - ETA: 0s - loss: 3.1484 - mae: 1.0634\n",
            "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0007290000503417104.\n",
            "128/128 [==============================] - 11s 86ms/step - loss: 3.1484 - mae: 1.0634 - val_loss: 43.9443 - val_mae: 5.0913 - lr: 8.1000e-04\n",
            "Epoch 27/150\n",
            "128/128 [==============================] - 11s 86ms/step - loss: 2.9262 - mae: 1.0545 - val_loss: 48.7371 - val_mae: 5.3286 - lr: 7.2900e-04\n",
            "Epoch 28/150\n",
            "128/128 [==============================] - 11s 86ms/step - loss: 2.3234 - mae: 0.9443 - val_loss: 46.1675 - val_mae: 5.1111 - lr: 7.2900e-04\n",
            "Epoch 29/150\n",
            "128/128 [==============================] - 11s 86ms/step - loss: 3.5343 - mae: 1.1264 - val_loss: 89.7367 - val_mae: 7.5515 - lr: 7.2900e-04\n",
            "Epoch 30/150\n",
            "128/128 [==============================] - 11s 85ms/step - loss: 5.8649 - mae: 1.4135 - val_loss: 32.6092 - val_mae: 4.1710 - lr: 7.2900e-04\n",
            "Epoch 31/150\n",
            "128/128 [==============================] - 11s 87ms/step - loss: 4.0519 - mae: 1.2395 - val_loss: 28.7952 - val_mae: 3.8431 - lr: 7.2900e-04\n",
            "Epoch 32/150\n",
            "128/128 [==============================] - 11s 86ms/step - loss: 4.4890 - mae: 1.3165 - val_loss: 50.3255 - val_mae: 5.8344 - lr: 7.2900e-04\n",
            "Epoch 33/150\n",
            "128/128 [==============================] - 11s 86ms/step - loss: 4.2887 - mae: 1.2572 - val_loss: 43.2138 - val_mae: 5.4293 - lr: 7.2900e-04\n",
            "Epoch 34/150\n",
            "128/128 [==============================] - 12s 92ms/step - loss: 2.6676 - mae: 1.0045 - val_loss: 24.9303 - val_mae: 3.7123 - lr: 7.2900e-04\n",
            "Epoch 35/150\n",
            "128/128 [==============================] - 11s 88ms/step - loss: 2.3577 - mae: 0.9362 - val_loss: 17.9533 - val_mae: 2.5189 - lr: 7.2900e-04\n",
            "Epoch 36/150\n",
            "128/128 [==============================] - 11s 85ms/step - loss: 2.2964 - mae: 0.9148 - val_loss: 17.7105 - val_mae: 2.5707 - lr: 7.2900e-04\n",
            "Epoch 37/150\n",
            "128/128 [==============================] - 11s 85ms/step - loss: 4.7847 - mae: 1.2762 - val_loss: 84.4391 - val_mae: 7.0198 - lr: 7.2900e-04\n",
            "Epoch 38/150\n",
            "128/128 [==============================] - 12s 90ms/step - loss: 4.7940 - mae: 1.2901 - val_loss: 59.1118 - val_mae: 5.7193 - lr: 7.2900e-04\n",
            "Epoch 39/150\n",
            "128/128 [==============================] - 11s 86ms/step - loss: 4.8905 - mae: 1.3242 - val_loss: 44.6337 - val_mae: 4.5559 - lr: 7.2900e-04\n",
            "Epoch 40/150\n",
            "128/128 [==============================] - ETA: 0s - loss: 3.9663 - mae: 1.1726\n",
            "Epoch 40: ReduceLROnPlateau reducing learning rate to 0.0006561000715009868.\n",
            "128/128 [==============================] - 11s 85ms/step - loss: 3.9663 - mae: 1.1726 - val_loss: 26.9127 - val_mae: 3.5588 - lr: 7.2900e-04\n",
            "Epoch 41/150\n",
            "128/128 [==============================] - 11s 86ms/step - loss: 2.5639 - mae: 0.9742 - val_loss: 25.7179 - val_mae: 3.6316 - lr: 6.5610e-04\n",
            "Epoch 42/150\n",
            "128/128 [==============================] - 11s 89ms/step - loss: 2.1072 - mae: 0.9111 - val_loss: 35.3843 - val_mae: 4.4082 - lr: 6.5610e-04\n",
            "Epoch 43/150\n",
            "128/128 [==============================] - 11s 86ms/step - loss: 1.5558 - mae: 0.8000 - val_loss: 19.9335 - val_mae: 2.8184 - lr: 6.5610e-04\n",
            "Epoch 44/150\n",
            "128/128 [==============================] - 12s 91ms/step - loss: 1.8491 - mae: 0.8926 - val_loss: 21.7482 - val_mae: 3.0749 - lr: 6.5610e-04\n",
            "Epoch 45/150\n",
            "128/128 [==============================] - ETA: 0s - loss: 1.2767 - mae: 0.7454\n",
            "Epoch 45: ReduceLROnPlateau reducing learning rate to 0.0005904900433961303.\n",
            "128/128 [==============================] - 11s 86ms/step - loss: 1.2767 - mae: 0.7454 - val_loss: 22.7323 - val_mae: 3.0251 - lr: 6.5610e-04\n",
            "Epoch 46/150\n",
            "128/128 [==============================] - 12s 91ms/step - loss: 1.0723 - mae: 0.6814 - val_loss: 19.8796 - val_mae: 2.6573 - lr: 5.9049e-04\n",
            "Epoch 47/150\n",
            "128/128 [==============================] - 12s 90ms/step - loss: 2.3989 - mae: 0.9530 - val_loss: 30.1010 - val_mae: 3.6866 - lr: 5.9049e-04\n",
            "Epoch 48/150\n",
            "128/128 [==============================] - 12s 91ms/step - loss: 2.2182 - mae: 0.9169 - val_loss: 19.3854 - val_mae: 3.0564 - lr: 5.9049e-04\n",
            "Epoch 49/150\n",
            "128/128 [==============================] - 12s 90ms/step - loss: 3.3655 - mae: 1.1427 - val_loss: 23.4188 - val_mae: 3.0306 - lr: 5.9049e-04\n",
            "Epoch 50/150\n",
            "128/128 [==============================] - ETA: 0s - loss: 2.1771 - mae: 0.9062\n",
            "Epoch 50: ReduceLROnPlateau reducing learning rate to 0.0005314410547725857.\n",
            "128/128 [==============================] - 11s 86ms/step - loss: 2.1771 - mae: 0.9062 - val_loss: 28.0516 - val_mae: 3.6012 - lr: 5.9049e-04\n",
            "Epoch 51/150\n",
            "128/128 [==============================] - 12s 91ms/step - loss: 1.6554 - mae: 0.8168 - val_loss: 19.2076 - val_mae: 2.6062 - lr: 5.3144e-04\n",
            "Epoch 52/150\n",
            "128/128 [==============================] - 12s 90ms/step - loss: 2.6548 - mae: 0.9718 - val_loss: 66.4917 - val_mae: 5.4888 - lr: 5.3144e-04\n",
            "Epoch 53/150\n",
            "128/128 [==============================] - 12s 90ms/step - loss: 2.0210 - mae: 0.8716 - val_loss: 55.8901 - val_mae: 4.9566 - lr: 5.3144e-04\n",
            "Epoch 54/150\n",
            "128/128 [==============================] - 11s 86ms/step - loss: 5.6740 - mae: 1.4167 - val_loss: 40.2030 - val_mae: 4.6425 - lr: 5.3144e-04\n",
            "Epoch 55/150\n",
            "128/128 [==============================] - ETA: 0s - loss: 2.4754 - mae: 0.9530\n",
            "Epoch 55: ReduceLROnPlateau reducing learning rate to 0.00047829695977270604.\n",
            "128/128 [==============================] - 11s 85ms/step - loss: 2.4754 - mae: 0.9530 - val_loss: 25.0059 - val_mae: 3.2056 - lr: 5.3144e-04\n",
            "Epoch 56/150\n",
            "128/128 [==============================] - 11s 87ms/step - loss: 1.4038 - mae: 0.7585 - val_loss: 18.9135 - val_mae: 2.6952 - lr: 4.7830e-04\n",
            "Epoch 57/150\n",
            "128/128 [==============================] - 11s 89ms/step - loss: 1.1202 - mae: 0.7007 - val_loss: 16.8542 - val_mae: 2.4238 - lr: 4.7830e-04\n",
            "Epoch 58/150\n",
            "128/128 [==============================] - 11s 86ms/step - loss: 1.0948 - mae: 0.6779 - val_loss: 17.5421 - val_mae: 2.6209 - lr: 4.7830e-04\n",
            "Epoch 59/150\n",
            "128/128 [==============================] - 11s 87ms/step - loss: 1.0836 - mae: 0.6932 - val_loss: 17.5849 - val_mae: 2.5999 - lr: 4.7830e-04\n",
            "Epoch 60/150\n",
            "128/128 [==============================] - 11s 87ms/step - loss: 1.1058 - mae: 0.7066 - val_loss: 19.1153 - val_mae: 2.9111 - lr: 4.7830e-04\n",
            "Epoch 61/150\n",
            "128/128 [==============================] - 12s 94ms/step - loss: 0.9515 - mae: 0.6418 - val_loss: 15.7932 - val_mae: 2.4141 - lr: 4.7830e-04\n",
            "Epoch 62/150\n",
            "128/128 [==============================] - 12s 91ms/step - loss: 1.5172 - mae: 0.7997 - val_loss: 35.1214 - val_mae: 3.6181 - lr: 4.7830e-04\n",
            "Epoch 63/150\n",
            "128/128 [==============================] - 12s 91ms/step - loss: 1.1902 - mae: 0.6876 - val_loss: 34.8857 - val_mae: 3.7645 - lr: 4.7830e-04\n",
            "Epoch 64/150\n",
            "128/128 [==============================] - 11s 88ms/step - loss: 1.5741 - mae: 0.7805 - val_loss: 19.7129 - val_mae: 2.4652 - lr: 4.7830e-04\n",
            "Epoch 65/150\n",
            "128/128 [==============================] - 12s 90ms/step - loss: 1.0757 - mae: 0.6718 - val_loss: 15.1455 - val_mae: 1.8875 - lr: 4.7830e-04\n",
            "Epoch 66/150\n",
            "128/128 [==============================] - 11s 88ms/step - loss: 0.9218 - mae: 0.6110 - val_loss: 19.7817 - val_mae: 2.1425 - lr: 4.7830e-04\n",
            "Epoch 67/150\n",
            "128/128 [==============================] - 11s 87ms/step - loss: 2.0587 - mae: 0.7997 - val_loss: 16.6551 - val_mae: 2.1491 - lr: 4.7830e-04\n",
            "Epoch 68/150\n",
            "128/128 [==============================] - 11s 87ms/step - loss: 1.4653 - mae: 0.7397 - val_loss: 19.3976 - val_mae: 2.4648 - lr: 4.7830e-04\n",
            "Epoch 69/150\n",
            "128/128 [==============================] - 12s 90ms/step - loss: 1.3706 - mae: 0.7468 - val_loss: 14.2454 - val_mae: 1.7296 - lr: 4.7830e-04\n",
            "Epoch 70/150\n",
            "128/128 [==============================] - 11s 87ms/step - loss: 1.0448 - mae: 0.6517 - val_loss: 15.1047 - val_mae: 1.7389 - lr: 4.7830e-04\n",
            "Epoch 71/150\n",
            "128/128 [==============================] - 11s 87ms/step - loss: 1.2164 - mae: 0.6578 - val_loss: 17.2914 - val_mae: 2.0053 - lr: 4.7830e-04\n",
            "Epoch 72/150\n",
            "128/128 [==============================] - 11s 87ms/step - loss: 2.2994 - mae: 0.8816 - val_loss: 20.9881 - val_mae: 2.4839 - lr: 4.7830e-04\n",
            "Epoch 73/150\n",
            "128/128 [==============================] - 11s 87ms/step - loss: 2.1952 - mae: 0.8372 - val_loss: 24.2951 - val_mae: 3.4820 - lr: 4.7830e-04\n",
            "Epoch 74/150\n",
            "128/128 [==============================] - ETA: 0s - loss: 2.8130 - mae: 0.9961\n",
            "Epoch 74: ReduceLROnPlateau reducing learning rate to 0.0004304672533180565.\n",
            "128/128 [==============================] - 11s 88ms/step - loss: 2.8130 - mae: 0.9961 - val_loss: 17.5513 - val_mae: 2.5955 - lr: 4.7830e-04\n",
            "Epoch 75/150\n",
            "128/128 [==============================] - 12s 90ms/step - loss: 1.6071 - mae: 0.7906 - val_loss: 16.5504 - val_mae: 2.2803 - lr: 4.3047e-04\n",
            "Epoch 76/150\n",
            "128/128 [==============================] - 11s 86ms/step - loss: 1.0443 - mae: 0.6531 - val_loss: 15.0697 - val_mae: 1.9995 - lr: 4.3047e-04\n",
            "Epoch 77/150\n",
            "128/128 [==============================] - 11s 87ms/step - loss: 0.6924 - mae: 0.5737 - val_loss: 13.8399 - val_mae: 1.9221 - lr: 4.3047e-04\n",
            "Epoch 78/150\n",
            "128/128 [==============================] - 11s 87ms/step - loss: 0.6987 - mae: 0.5512 - val_loss: 13.7010 - val_mae: 1.7873 - lr: 4.3047e-04\n",
            "Epoch 79/150\n",
            "128/128 [==============================] - 11s 89ms/step - loss: 0.6531 - mae: 0.5349 - val_loss: 13.0670 - val_mae: 1.6578 - lr: 4.3047e-04\n",
            "Epoch 80/150\n",
            "128/128 [==============================] - 12s 94ms/step - loss: 0.5777 - mae: 0.5239 - val_loss: 12.5724 - val_mae: 1.6207 - lr: 4.3047e-04\n",
            "Epoch 81/150\n",
            "128/128 [==============================] - 11s 89ms/step - loss: 0.6440 - mae: 0.5252 - val_loss: 11.4085 - val_mae: 1.4377 - lr: 4.3047e-04\n",
            "Epoch 82/150\n",
            "128/128 [==============================] - 11s 87ms/step - loss: 0.9570 - mae: 0.6620 - val_loss: 14.4705 - val_mae: 1.9927 - lr: 4.3047e-04\n",
            "Epoch 83/150\n",
            "128/128 [==============================] - 12s 91ms/step - loss: 1.1544 - mae: 0.6517 - val_loss: 24.8493 - val_mae: 3.3868 - lr: 4.3047e-04\n",
            "Epoch 84/150\n",
            "128/128 [==============================] - 12s 92ms/step - loss: 2.4000 - mae: 0.8784 - val_loss: 16.8726 - val_mae: 2.2054 - lr: 4.3047e-04\n",
            "Epoch 85/150\n",
            "128/128 [==============================] - 11s 87ms/step - loss: 1.4064 - mae: 0.7306 - val_loss: 26.5816 - val_mae: 3.1433 - lr: 4.3047e-04\n",
            "Epoch 86/150\n",
            "128/128 [==============================] - ETA: 0s - loss: 1.1732 - mae: 0.6505\n",
            "Epoch 86: ReduceLROnPlateau reducing learning rate to 0.00038742052274756136.\n",
            "128/128 [==============================] - 11s 87ms/step - loss: 1.1732 - mae: 0.6505 - val_loss: 16.9566 - val_mae: 2.0280 - lr: 4.3047e-04\n",
            "Epoch 87/150\n",
            "128/128 [==============================] - 11s 87ms/step - loss: 2.0510 - mae: 0.8594 - val_loss: 18.6616 - val_mae: 2.3827 - lr: 3.8742e-04\n",
            "Epoch 88/150\n",
            "128/128 [==============================] - 11s 86ms/step - loss: 1.1548 - mae: 0.6821 - val_loss: 16.4478 - val_mae: 2.2888 - lr: 3.8742e-04\n",
            "Epoch 89/150\n",
            "128/128 [==============================] - 11s 88ms/step - loss: 0.9874 - mae: 0.6346 - val_loss: 13.3182 - val_mae: 1.8278 - lr: 3.8742e-04\n",
            "Epoch 90/150\n",
            "128/128 [==============================] - 12s 91ms/step - loss: 0.9608 - mae: 0.6427 - val_loss: 15.3891 - val_mae: 2.0144 - lr: 3.8742e-04\n",
            "Epoch 91/150\n",
            "128/128 [==============================] - ETA: 0s - loss: 0.8534 - mae: 0.5973\n",
            "Epoch 91: ReduceLROnPlateau reducing learning rate to 0.0003486784757114947.\n",
            "128/128 [==============================] - 11s 86ms/step - loss: 0.8534 - mae: 0.5973 - val_loss: 14.1468 - val_mae: 1.7108 - lr: 3.8742e-04\n",
            "Epoch 92/150\n",
            "128/128 [==============================] - 11s 87ms/step - loss: 0.8300 - mae: 0.5958 - val_loss: 13.0861 - val_mae: 1.7569 - lr: 3.4868e-04\n",
            "Epoch 93/150\n",
            "128/128 [==============================] - 11s 86ms/step - loss: 0.9546 - mae: 0.6131 - val_loss: 18.5974 - val_mae: 2.7353 - lr: 3.4868e-04\n",
            "Epoch 94/150\n",
            "128/128 [==============================] - 12s 91ms/step - loss: 0.8780 - mae: 0.5972 - val_loss: 15.2135 - val_mae: 1.9997 - lr: 3.4868e-04\n",
            "Epoch 95/150\n",
            "128/128 [==============================] - 11s 86ms/step - loss: 1.4682 - mae: 0.7247 - val_loss: 18.0069 - val_mae: 2.3347 - lr: 3.4868e-04\n",
            "Epoch 96/150\n",
            "128/128 [==============================] - ETA: 0s - loss: 1.2661 - mae: 0.6564\n",
            "Epoch 96: ReduceLROnPlateau reducing learning rate to 0.00031381062290165574.\n",
            "128/128 [==============================] - 11s 86ms/step - loss: 1.2661 - mae: 0.6564 - val_loss: 13.3249 - val_mae: 1.7490 - lr: 3.4868e-04\n",
            "Epoch 97/150\n",
            "128/128 [==============================] - 11s 87ms/step - loss: 1.1390 - mae: 0.6608 - val_loss: 14.2938 - val_mae: 1.9565 - lr: 3.1381e-04\n",
            "Epoch 98/150\n",
            "128/128 [==============================] - 11s 87ms/step - loss: 0.9668 - mae: 0.6162 - val_loss: 15.5633 - val_mae: 1.9971 - lr: 3.1381e-04\n",
            "Epoch 99/150\n",
            "128/128 [==============================] - 11s 87ms/step - loss: 0.7939 - mae: 0.5986 - val_loss: 13.0656 - val_mae: 1.6383 - lr: 3.1381e-04\n",
            "Epoch 100/150\n",
            "128/128 [==============================] - 11s 87ms/step - loss: 0.9297 - mae: 0.6154 - val_loss: 15.1179 - val_mae: 2.0046 - lr: 3.1381e-04\n",
            "Epoch 101/150\n",
            "128/128 [==============================] - ETA: 0s - loss: 0.7272 - mae: 0.5688\n",
            "Epoch 101: ReduceLROnPlateau reducing learning rate to 0.0002824295632308349.\n",
            "128/128 [==============================] - 12s 92ms/step - loss: 0.7272 - mae: 0.5688 - val_loss: 13.6378 - val_mae: 1.6761 - lr: 3.1381e-04\n",
            "Epoch 102/150\n",
            "128/128 [==============================] - 11s 87ms/step - loss: 0.9230 - mae: 0.6396 - val_loss: 16.8244 - val_mae: 2.2613 - lr: 2.8243e-04\n",
            "Epoch 103/150\n",
            "128/128 [==============================] - 11s 87ms/step - loss: 1.3350 - mae: 0.6765 - val_loss: 16.9001 - val_mae: 2.0687 - lr: 2.8243e-04\n",
            "Epoch 104/150\n",
            "128/128 [==============================] - 11s 88ms/step - loss: 1.0403 - mae: 0.6340 - val_loss: 14.0581 - val_mae: 1.7392 - lr: 2.8243e-04\n",
            "Epoch 105/150\n",
            "128/128 [==============================] - 11s 87ms/step - loss: 1.0662 - mae: 0.6267 - val_loss: 16.0664 - val_mae: 2.0053 - lr: 2.8243e-04\n",
            "Epoch 106/150\n",
            "127/128 [============================>.] - ETA: 0s - loss: 0.7738 - mae: 0.5670\n",
            "Epoch 106: ReduceLROnPlateau reducing learning rate to 0.00025418660952709616.\n",
            "128/128 [==============================] - 11s 87ms/step - loss: 0.7753 - mae: 0.5673 - val_loss: 13.5624 - val_mae: 1.6529 - lr: 2.8243e-04\n",
            "Epoch 107/150\n",
            "128/128 [==============================] - 11s 87ms/step - loss: 0.6861 - mae: 0.5435 - val_loss: 14.2930 - val_mae: 1.7088 - lr: 2.5419e-04\n",
            "Epoch 108/150\n",
            "128/128 [==============================] - 11s 86ms/step - loss: 0.5919 - mae: 0.4974 - val_loss: 13.4393 - val_mae: 1.5399 - lr: 2.5419e-04\n",
            "Epoch 109/150\n",
            "128/128 [==============================] - 11s 87ms/step - loss: 0.5167 - mae: 0.4916 - val_loss: 12.4763 - val_mae: 1.4700 - lr: 2.5419e-04\n",
            "Epoch 110/150\n",
            "128/128 [==============================] - 12s 92ms/step - loss: 0.7188 - mae: 0.5311 - val_loss: 14.4087 - val_mae: 1.7454 - lr: 2.5419e-04\n",
            "Epoch 111/150\n",
            "128/128 [==============================] - ETA: 0s - loss: 0.5562 - mae: 0.5072\n",
            "Epoch 111: ReduceLROnPlateau reducing learning rate to 0.00022876793809700757.\n",
            "128/128 [==============================] - 11s 87ms/step - loss: 0.5562 - mae: 0.5072 - val_loss: 12.8036 - val_mae: 1.4691 - lr: 2.5419e-04\n",
            "Epoch 112/150\n",
            "128/128 [==============================] - 11s 88ms/step - loss: 0.4974 - mae: 0.4697 - val_loss: 12.7189 - val_mae: 1.4608 - lr: 2.2877e-04\n",
            "Epoch 113/150\n",
            "128/128 [==============================] - 12s 95ms/step - loss: 0.5336 - mae: 0.4823 - val_loss: 12.2784 - val_mae: 1.4213 - lr: 2.2877e-04\n",
            "Epoch 114/150\n",
            "128/128 [==============================] - 12s 91ms/step - loss: 0.5072 - mae: 0.4811 - val_loss: 12.2146 - val_mae: 1.3870 - lr: 2.2877e-04\n",
            "Epoch 115/150\n",
            "128/128 [==============================] - 12s 90ms/step - loss: 0.4884 - mae: 0.4734 - val_loss: 11.9837 - val_mae: 1.3211 - lr: 2.2877e-04\n",
            "Epoch 116/150\n",
            "128/128 [==============================] - 11s 87ms/step - loss: 0.4601 - mae: 0.4650 - val_loss: 14.9934 - val_mae: 1.6885 - lr: 2.2877e-04\n",
            "Epoch 117/150\n",
            "128/128 [==============================] - 11s 87ms/step - loss: 0.5431 - mae: 0.4865 - val_loss: 12.7345 - val_mae: 1.4268 - lr: 2.2877e-04\n",
            "Epoch 118/150\n",
            "128/128 [==============================] - 12s 90ms/step - loss: 0.4384 - mae: 0.4543 - val_loss: 12.3160 - val_mae: 1.3738 - lr: 2.2877e-04\n",
            "Epoch 119/150\n",
            "128/128 [==============================] - 11s 87ms/step - loss: 0.3852 - mae: 0.4360 - val_loss: 12.0107 - val_mae: 1.3299 - lr: 2.2877e-04\n",
            "Epoch 120/150\n",
            "128/128 [==============================] - ETA: 0s - loss: 0.5029 - mae: 0.4642\n",
            "Epoch 120: ReduceLROnPlateau reducing learning rate to 0.00020589114428730683.\n",
            "128/128 [==============================] - 11s 87ms/step - loss: 0.5029 - mae: 0.4642 - val_loss: 11.8745 - val_mae: 1.4370 - lr: 2.2877e-04\n",
            "Epoch 121/150\n",
            "128/128 [==============================] - 11s 87ms/step - loss: 0.4112 - mae: 0.4433 - val_loss: 11.6812 - val_mae: 1.3766 - lr: 2.0589e-04\n",
            "Epoch 122/150\n",
            "128/128 [==============================] - 12s 90ms/step - loss: 0.3945 - mae: 0.4286 - val_loss: 11.4220 - val_mae: 1.3076 - lr: 2.0589e-04\n",
            "Epoch 123/150\n",
            "128/128 [==============================] - 11s 87ms/step - loss: 0.4240 - mae: 0.4410 - val_loss: 12.0138 - val_mae: 1.4634 - lr: 2.0589e-04\n",
            "Epoch 124/150\n",
            "128/128 [==============================] - 12s 92ms/step - loss: 0.4273 - mae: 0.4414 - val_loss: 11.4401 - val_mae: 1.3571 - lr: 2.0589e-04\n",
            "Epoch 125/150\n",
            "128/128 [==============================] - 11s 87ms/step - loss: 0.7700 - mae: 0.5634 - val_loss: 12.2531 - val_mae: 1.5555 - lr: 2.0589e-04\n",
            "Epoch 126/150\n",
            "128/128 [==============================] - 12s 91ms/step - loss: 0.4988 - mae: 0.4676 - val_loss: 11.5007 - val_mae: 1.4081 - lr: 2.0589e-04\n",
            "Epoch 127/150\n",
            "128/128 [==============================] - 12s 91ms/step - loss: 0.4290 - mae: 0.4400 - val_loss: 11.0583 - val_mae: 1.3018 - lr: 2.0589e-04\n",
            "Epoch 128/150\n",
            "128/128 [==============================] - 11s 87ms/step - loss: 0.4209 - mae: 0.4456 - val_loss: 12.4993 - val_mae: 1.5858 - lr: 2.0589e-04\n",
            "Epoch 129/150\n",
            "128/128 [==============================] - 12s 92ms/step - loss: 0.4738 - mae: 0.4510 - val_loss: 11.5078 - val_mae: 1.4097 - lr: 2.0589e-04\n",
            "Epoch 130/150\n",
            "128/128 [==============================] - 12s 91ms/step - loss: 0.6723 - mae: 0.5205 - val_loss: 12.2998 - val_mae: 1.4214 - lr: 2.0589e-04\n",
            "Epoch 131/150\n",
            "128/128 [==============================] - 11s 88ms/step - loss: 0.5062 - mae: 0.4739 - val_loss: 13.2506 - val_mae: 1.7307 - lr: 2.0589e-04\n",
            "Epoch 132/150\n",
            "128/128 [==============================] - ETA: 0s - loss: 0.4830 - mae: 0.4754\n",
            "Epoch 132: ReduceLROnPlateau reducing learning rate to 0.00018530203378759326.\n",
            "128/128 [==============================] - 11s 88ms/step - loss: 0.4830 - mae: 0.4754 - val_loss: 12.2417 - val_mae: 1.4609 - lr: 2.0589e-04\n",
            "Epoch 133/150\n",
            "128/128 [==============================] - 11s 87ms/step - loss: 0.5859 - mae: 0.5004 - val_loss: 11.1846 - val_mae: 1.4992 - lr: 1.8530e-04\n",
            "Epoch 134/150\n",
            "128/128 [==============================] - 11s 88ms/step - loss: 0.4652 - mae: 0.4710 - val_loss: 10.8593 - val_mae: 1.3375 - lr: 1.8530e-04\n",
            "Epoch 135/150\n",
            "128/128 [==============================] - 11s 89ms/step - loss: 0.4724 - mae: 0.4479 - val_loss: 10.6469 - val_mae: 1.2614 - lr: 1.8530e-04\n",
            "Epoch 136/150\n",
            "128/128 [==============================] - 11s 88ms/step - loss: 0.3717 - mae: 0.4305 - val_loss: 10.9766 - val_mae: 1.2832 - lr: 1.8530e-04\n",
            "Epoch 137/150\n",
            "128/128 [==============================] - 12s 95ms/step - loss: 0.4099 - mae: 0.4334 - val_loss: 10.7407 - val_mae: 1.2528 - lr: 1.8530e-04\n",
            "Epoch 138/150\n",
            "128/128 [==============================] - 12s 95ms/step - loss: 0.3773 - mae: 0.4238 - val_loss: 10.4593 - val_mae: 1.1848 - lr: 1.8530e-04\n",
            "Epoch 139/150\n",
            "128/128 [==============================] - 12s 95ms/step - loss: 0.4223 - mae: 0.4236 - val_loss: 10.5899 - val_mae: 1.1743 - lr: 1.8530e-04\n",
            "Epoch 140/150\n",
            "128/128 [==============================] - 12s 92ms/step - loss: 0.3943 - mae: 0.4160 - val_loss: 10.8196 - val_mae: 1.1902 - lr: 1.8530e-04\n",
            "Epoch 141/150\n",
            "128/128 [==============================] - 12s 91ms/step - loss: 0.3704 - mae: 0.4223 - val_loss: 11.0482 - val_mae: 1.3065 - lr: 1.8530e-04\n",
            "Epoch 142/150\n",
            "128/128 [==============================] - 12s 92ms/step - loss: 0.3569 - mae: 0.4161 - val_loss: 10.3697 - val_mae: 1.2047 - lr: 1.8530e-04\n",
            "Epoch 143/150\n",
            "128/128 [==============================] - 11s 88ms/step - loss: 0.4024 - mae: 0.4046 - val_loss: 10.4552 - val_mae: 1.1957 - lr: 1.8530e-04\n",
            "Epoch 144/150\n",
            "128/128 [==============================] - 12s 90ms/step - loss: 0.3388 - mae: 0.4019 - val_loss: 10.5144 - val_mae: 1.1662 - lr: 1.8530e-04\n",
            "Epoch 145/150\n",
            "128/128 [==============================] - 11s 87ms/step - loss: 0.7240 - mae: 0.5156 - val_loss: 12.0334 - val_mae: 1.4909 - lr: 1.8530e-04\n",
            "Epoch 146/150\n",
            "128/128 [==============================] - 11s 87ms/step - loss: 0.4500 - mae: 0.4397 - val_loss: 12.1937 - val_mae: 1.3697 - lr: 1.8530e-04\n",
            "Epoch 147/150\n",
            "128/128 [==============================] - 11s 88ms/step - loss: 0.5237 - mae: 0.4396 - val_loss: 12.5704 - val_mae: 1.3708 - lr: 1.8530e-04\n",
            "Epoch 148/150\n",
            "128/128 [==============================] - 11s 88ms/step - loss: 0.4099 - mae: 0.4257 - val_loss: 12.0073 - val_mae: 1.3295 - lr: 1.8530e-04\n",
            "Epoch 149/150\n",
            "128/128 [==============================] - ETA: 0s - loss: 0.3469 - mae: 0.4059\n",
            "Epoch 149: ReduceLROnPlateau reducing learning rate to 0.00016677183302817866.\n",
            "128/128 [==============================] - 11s 88ms/step - loss: 0.3469 - mae: 0.4059 - val_loss: 11.2955 - val_mae: 1.2809 - lr: 1.8530e-04\n",
            "Epoch 150/150\n",
            "128/128 [==============================] - 11s 87ms/step - loss: 0.3406 - mae: 0.3978 - val_loss: 11.1895 - val_mae: 1.2277 - lr: 1.6677e-04\n"
          ]
        }
      ],
      "source": [
        "EPOCHS=150\n",
        "BATCH_SIZE=64\n",
        "\n",
        "history=model.fit(X_train,\n",
        "                 Y_train,\n",
        "                 validation_data=(X_test,Y_test),\n",
        "                 batch_size=BATCH_SIZE,\n",
        "                 epochs=EPOCHS,\n",
        "                 callbacks=[model_checkpoint,reduce_lr],\n",
        "                  steps_per_epoch=128\n",
        "                  \n",
        "\n",
        "                 )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "yJJZWaRaND22",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8bd654a5-c3d8-472c-e44b-e476552bbedb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[12.759879  ],\n",
              "       [15.578155  ],\n",
              "       [13.156936  ],\n",
              "       [19.89915   ],\n",
              "       [ 9.682581  ],\n",
              "       [18.785875  ],\n",
              "       [17.665398  ],\n",
              "       [ 6.8373237 ],\n",
              "       [19.410976  ],\n",
              "       [11.27731   ],\n",
              "       [ 6.2635107 ],\n",
              "       [ 0.06841336],\n",
              "       [ 0.85455227],\n",
              "       [15.999194  ],\n",
              "       [ 5.2215505 ],\n",
              "       [27.208534  ],\n",
              "       [ 5.0695086 ],\n",
              "       [17.141598  ],\n",
              "       [ 9.377102  ],\n",
              "       [ 2.7974699 ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "prediction_val=model.predict(X_test,batch_size=64)\n",
        "prediction_val[:20]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_weights(ckp_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CGmunyexSx1y",
        "outputId": "c02d71bf-648c-48e9-b221-5845004e2d6f"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fd0f816be50>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "OGRvXHTIND57",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "483bdf4d-cc8f-4d85-ce51-2a0bb913f503"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Function `_wrapped_model` contains input name(s) mobilenetv2_1.00_96_input with unsupported characters which will be renamed to mobilenetv2_1_00_96_input in the SavedModel.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpc9nhhmyp/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpc9nhhmyp/assets\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        }
      ],
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Save the model.\n",
        "with open('model.tflite', 'wb') as f:\n",
        "  f.write(tflite_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iIhOP2RoND80"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "face_recognition_test.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOlxOJwww2GpXMtGvAeP2hR",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}